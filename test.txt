from pyspark.sql import functions as F

def compute_pct_change_from_windows(df, window_pairs):
    """
    Automatically computes percentage change features using inferred prefixes from window suffixes.
    
    Args:
        df (DataFrame): Input PySpark DataFrame.
        window_pairs (List[Tuple[str, str]]): List of time window suffix pairs.
    
    Returns:
        DataFrame: DataFrame with added percentage change features.
    """
    # 1. Flatten all unique suffixes from window pairs
    window_suffixes = {w for pair in window_pairs for w in pair}
    
    # 2. Pre-compute columns and build prefix map
    col_set = set(df.columns)
    prefix_map = {}

    for col in col_set:
        for suffix in window_suffixes:
            if col.endswith(suffix):
                prefix = col[: -len(suffix)]
                prefix_map.setdefault(prefix, set()).add(suffix)
                break  # One match per column is enough

    # 3. Compute percentage change features only for existing col pairs
    for prefix, suffixes in prefix_map.items():
        for win1, win2 in window_pairs:
            if win1 in suffixes and win2 in suffixes:
                col1, col2 = f"{prefix}{win1}", f"{prefix}{win2}"
                new_col = f"{prefix}pct_change_{win1}_to_{win2}"
                df = df.withColumn(
                    new_col,
                    F.when(F.col(col2) != 0, (F.col(col1) - F.col(col2)) / F.col(col2)).otherwise(None)
                )

    return df
