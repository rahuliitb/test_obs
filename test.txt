from pyspark.sql import functions as F

# Step 1: Expand accounts to active months
accounts_exp = accounts.withColumn(
    "active_months",
    F.expr("sequence(open_date, coalesce(close_date, current_date()), interval 1 month)")
).withColumn("active_month", F.explode("active_months"))

# Step 2: Collect unique active months per application
accounts_active = (accounts_exp.groupBy("application_id")
                   .agg(F.collect_set("active_month").alias("active_months_set")))

# Step 3: Generate feature months per application
apps = apps.withColumn("feature_start", F.add_months("app_date", -12)) \
           .withColumn("feature_end", F.add_months("app_date", -1)) \
           .withColumn("feature_months", 
                       F.expr("sequence(feature_start, feature_end, interval 1 month)"))

# Step 4: Join accounts with applications
joined = apps.join(accounts_active, "application_id", "left")

# Step 5: Check coverage
valid = joined.withColumn(
    "is_valid",
    F.size(F.array_except("feature_months", "active_months_set")) == 0
)
