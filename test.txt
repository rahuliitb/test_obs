from pyspark.sql import functions as F

def compute_pct_change_from_windows(df, window_pairs):
    """
    Automatically detects column prefixes based on window suffixes,
    and computes percentage change features for all matching prefix-window combinations.

    Args:
        df (DataFrame): The input PySpark DataFrame.
        window_pairs (List[Tuple[str, str]]): Time window suffix pairs, e.g., [('1_3m', '4_6m')].

    Returns:
        DataFrame: Transformed DataFrame with new percentage change features.
    """
    # Step 1: Extract unique time window parts
    window_parts = list(set(w for pair in window_pairs for w in pair))

    # Step 2: Infer prefixes by removing window suffixes from column names
    prefixes = list(set(
        col.replace(w, '') 
        for col in df.columns 
        for w in window_parts 
        if col.endswith(w)
    ))

    # Step 3: Compute percentage change features
    for prefix in prefixes:
        for win1, win2 in window_pairs:
            col1 = f"{prefix}{win1}"
            col2 = f"{prefix}{win2}"
            if col1 in df.columns and col2 in df.columns:
                new_col = f"{prefix}pct_change_{win1}_to_{win2}"
                df = df.withColumn(
                    new_col,
                    F.when(F.col(col2) != 0, (F.col(col1) - F.col(col2)) / F.col(col2)).otherwise(None)
                )

    return df
