from pyspark.sql.functions import col, when

def compute_percentage_change_features(df, column_prefixes, window_pairs):
    """
    Compute percentage change features for each column prefix over given window pairs.
    
    Args:
        df (DataFrame): The input DataFrame.
        column_prefixes (List[str]): List of column name prefixes like 'avg_monthly_balance'.
        window_pairs (List[Tuple[str, str]]): List of tuples like ('1_3m', '4_6m').

    Returns:
        DataFrame: Input DataFrame with added percentage change features.
    """
    for prefix in column_prefixes:
        for win1, win2 in window_pairs:
            col1 = f"{prefix}_{win1}"
            col2 = f"{prefix}_{win2}"
            new_col = f"{prefix}_pct_change_{win1}_to_{win2}"

            df = df.withColumn(
                new_col,
                when(col(col2) != 0, (col(col1) - col(col2)) / col(col2)).otherwise(None)
            )
    return df
