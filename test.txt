from __future__ import annotations

from pathlib import Path
from typing import Literal

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import shap
from loguru import logger
from sklearn.base import clone
from sklearn.model_selection import GroupKFold


DatasetType = Literal["it", "oos", "oot"]


# ------------------------------------------------------------------
# LightGBM native importance helper
# ------------------------------------------------------------------
def compute_lgbm_importance(model) -> pd.DataFrame:
    if hasattr(model, "booster_"):
        booster = model.booster_
    elif hasattr(model, "_Booster"):
        booster = model._Booster
    else:
        raise TypeError("Model does not appear to be a LightGBM model")

    return (
        pd.DataFrame(
            {
                "feature": booster.feature_name(),
                "gain": booster.feature_importance("gain"),
                "split": booster.feature_importance("split"),
            }
        )
        .sort_values("gain", ascending=False)
        .reset_index(drop=True)
    )


# ------------------------------------------------------------------
# CV SHAP Explainer
# ------------------------------------------------------------------
class CVShapExplainer:
    """
    Final, minimal, CV-safe explainability pipeline.

    Includes:
    - SHAP: IT, OOS, OOT
    - LightGBM native importance: IT, OOS (CV-mean), OOT
    - Automatic plot + table export
    """

    def __init__(
        self,
        best_model,
        n_splits: int = 5,
        max_display: int = 35,
    ) -> None:
        self.best_model = best_model
        self.base_estimator = clone(best_model)
        self.n_splits = n_splits
        self.max_display = max_display

        self.shap_it: np.ndarray | None = None
        self.shap_oos: np.ndarray | None = None
        self.shap_oot: np.ndarray | None = None

        self.X_it: pd.DataFrame | None = None
        self.X_oos: pd.DataFrame | None = None
        self.X_oot: pd.DataFrame | None = None

        self._cv_importances: list[pd.DataFrame] = []

        logger.info(
            "CVShapExplainer initialized (cv_folds={}, max_display={})",
            n_splits,
            max_display,
        )

    # ------------------------------------------------------------------
    # IT SHAP (diagnostic)
    # ------------------------------------------------------------------
    def fit_it(self, X_it: pd.DataFrame) -> "CVShapExplainer":
        logger.info("Computing IT SHAP values (rows={})", len(X_it))

        explainer = shap.TreeExplainer(self.best_model)
        shap_vals = explainer.shap_values(X_it)

        if isinstance(shap_vals, list):
            shap_vals = shap_vals[1]  # positive class

        self.shap_it = shap_vals
        self.X_it = X_it

        return self

    # ------------------------------------------------------------------
    # CV-OOS SHAP
    # ------------------------------------------------------------------
    def fit_cv_oos(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        groups: pd.Series,
    ) -> "CVShapExplainer":
        logger.info(
            "Computing CV-OOS SHAP (folds={}, rows={})",
            self.n_splits,
            len(X),
        )

        gkf = GroupKFold(n_splits=self.n_splits)

        shap_values: list[np.ndarray] = []
        X_values: list[pd.DataFrame] = []

        for train_idx, val_idx in gkf.split(X, y, groups):
            model = clone(self.base_estimator)
            model.fit(X.iloc[train_idx], y.iloc[train_idx])

            explainer = shap.TreeExplainer(model)
            shap_vals = explainer.shap_values(X.iloc[val_idx])

            if isinstance(shap_vals, list):
                shap_vals = shap_vals[1]

            shap_values.append(shap_vals)
            X_values.append(X.iloc[val_idx])

            self._cv_importances.append(
                compute_lgbm_importance(model)
            )

        self.shap_oos = np.vstack(shap_values)
        self.X_oos = pd.concat(X_values, axis=0)

        return self

    # ------------------------------------------------------------------
    # OOT SHAP
    # ------------------------------------------------------------------
    def fit_oot(self, X_oot: pd.DataFrame) -> "CVShapExplainer":
        logger.info("Computing OOT SHAP values (rows={})", len(X_oot))

        explainer = shap.TreeExplainer(self.best_model)
        shap_vals = explainer.shap_values(X_oot)

        if isinstance(shap_vals, list):
            shap_vals = shap_vals[1]

        self.shap_oot = shap_vals
        self.X_oot = X_oot

        return self

    # ------------------------------------------------------------------
    # LightGBM native importance
    # ------------------------------------------------------------------
    def get_lgbm_importance(self, dataset: DatasetType) -> pd.DataFrame:
        if dataset in {"it", "oot"}:
            df = compute_lgbm_importance(self.best_model)

        elif dataset == "oos":
            df = (
                pd.concat(self._cv_importances, axis=0)
                .groupby("feature", as_index=False)
                .mean()
                .sort_values("gain", ascending=False)
            )
        else:
            raise ValueError("dataset must be one of: 'it', 'oos', 'oot'")

        df["dataset"] = dataset
        return df.reset_index(drop=True)

    # ------------------------------------------------------------------
    # Explainability artifact export
    # ------------------------------------------------------------------
    def export_explainability_artifact(self, output_dir: str | Path) -> None:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        if self.shap_oos is None or self.X_oos is None:
            raise RuntimeError("Run fit_cv_oos before exporting artifacts")

        logger.info("Exporting explainability artifact to {}", output_dir)

        # --------------------
        # SHAP plots
        # --------------------
        for name, shap_vals, X in (
            ("it", self.shap_it, self.X_it),
            ("oos", self.shap_oos, self.X_oos),
            ("oot", self.shap_oot, self.X_oot),
        ):
            if shap_vals is None or X is None:
                continue

            shap.summary_plot(
                shap_vals,
                X,
                max_display=self.max_display,
                show=False,
            )
            plt.savefig(
                output_dir / f"shap_beeswarm_{name}.png",
                bbox_inches="tight",
            )
            plt.close()

        shap.summary_plot(
            self.shap_oos,
            self.X_oos,
            plot_type="bar",
            max_display=self.max_display,
            show=False,
        )
        plt.savefig(
            output_dir / "shap_bar_oos.png",
            bbox_inches="tight",
        )
        plt.close()

        # --------------------
        # LightGBM importance plots
        # --------------------
        for dataset in ("it", "oos", "oot"):
            df = self.get_lgbm_importance(dataset).head(self.max_display)

            for col in ("gain", "split"):
                (
                    df.sort_values(col)
                    .plot(
                        kind="barh",
                        x="feature",
                        y=col,
                        figsize=(8, max(4, len(df) * 0.3)),
                        legend=False,
                        title=f"LightGBM {col} importance ({dataset})",
                    )
                )
                plt.savefig(
                    output_dir / f"lgbm_{col}_{dataset}.png",
                    bbox_inches="tight",
                )
                plt.close()

        # --------------------
        # Tables
        # --------------------
        self.get_lgbm_importance("it").to_csv(
            output_dir / "lgbm_importance_it.csv",
            index=False,
        )
        self.get_lgbm_importance("oos").to_csv(
            output_dir / "lgbm_importance_oos.csv",
            index=False,
        )
        self.get_lgbm_importance("oot").to_csv(
            output_dir / "lgbm_importance_oot.csv",
            index=False,
        )

        logger.info("Explainability artifact export completed")


def run_explainability(
    best_model,
    X_it: pd.DataFrame,
    y_it: pd.Series,
    groups: pd.Series,
    X_oot: pd.DataFrame,
    output_dir: str | Path,
    *,
    n_splits: int = 5,
    max_display: int = 35,
) -> CVShapExplainer:
    """
    Run end-to-end explainability for IT, OOS, and OOT.

    Returns the fitted CVShapExplainer for interactive use.
    """
    logger.info("Starting end-to-end explainability run")

    explainer = CVShapExplainer(
        best_model=best_model,
        n_splits=n_splits,
        max_display=max_display,
    )

    explainer.fit_it(X_it)
    explainer.fit_cv_oos(X_it, y_it, groups)
    explainer.fit_oot(X_oot)

    explainer.export_explainability_artifact(output_dir)

    logger.info("Explainability run completed")

    return explainer

import shutil
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import shap
from loguru import logger


def export_shap_dependence_plots(
    explainer: CVShapExplainer,
    output_dir: str | Path,
    *,
    datasets: tuple[str, ...] = ("it", "oos", "oot"),
    max_features: int = 10,
) -> None:
    """
    Export SHAP dependence plots with automatic interaction coloring.

    If the output directory already exists, it is removed and recreated.
    Uses existing SHAP values (no interaction values required).
    """
    output_dir = Path(output_dir)

    # Clean existing directory (explicit and intentional)
    if output_dir.exists():
        logger.info(
            "Output directory '{}' exists. Removing it.",
            output_dir,
        )
        shutil.rmtree(output_dir)

    output_dir.mkdir(parents=True, exist_ok=True)

    logger.info("Exporting SHAP dependence plots (auto-interaction)")

    data_map = {
        "it": (explainer.shap_it, explainer.X_it),
        "oos": (explainer.shap_oos, explainer.X_oos),
        "oot": (explainer.shap_oot, explainer.X_oot),
    }

    for dataset in datasets:
        shap_vals, X = data_map.get(dataset, (None, None))
        if shap_vals is None or X is None:
            logger.debug(
                "Skipping dataset '{}' (SHAP values not available)",
                dataset,
            )
            continue

        dataset_dir = output_dir / dataset
        dataset_dir.mkdir(exist_ok=True)

        # Select top features by mean |SHAP|
        mean_abs = np.abs(shap_vals).mean(axis=0)
        top_features = (
            pd.Series(mean_abs, index=X.columns)
            .sort_values(ascending=False)
            .head(max_features)
            .index
        )

        logger.info(
            "Dataset '{}' | exporting dependence plots for {} features",
            dataset,
            len(top_features),
        )

        for feature in top_features:
            plt.figure()
            shap.dependence_plot(
                feature,
                shap_vals,
                X,
                show=False,
            )
            plt.savefig(
                dataset_dir / f"dependence_{feature}.png",
                bbox_inches="tight",
            )
            plt.close()

    logger.info("SHAP dependence plot export completed")


def _save_shap_summary_plot(
    self,
    shap_vals: np.ndarray,
    X: pd.DataFrame,
    path: Path,
    *,
    plot_type: str | None = None,
) -> None:
    """
    Save a SHAP summary plot with layout fixes for long feature names.
    """
    plt.figure(figsize=(14, 0.35 * self.max_display))

    shap.summary_plot(
        shap_vals,
        X,
        plot_type=plot_type,
        max_display=self.max_display,
        show=False,
    )

    # Reduce font size of feature names
    ax = plt.gca()
    for label in ax.get_yticklabels():
        label.set_fontsize(8)

    # Add space for long feature names
    plt.gcf().subplots_adjust(left=0.35)

    plt.savefig(path, bbox_inches="tight")
    plt.close()

    self._save_shap_summary_plot(
        shap_vals,
        X,
        output_dir / f"shap_beeswarm_{name}.png",
    )
self._save_shap_summary_plot(
    self.shap_oos,
    self.X_oos,
    output_dir / "shap_bar_oos.png",
    plot_type="bar",
)

def _save_shap_plot(
    self,
    *,
    shap_vals: np.ndarray,
    X: pd.DataFrame,
    path: Path,
    plot_kind: Literal["summary", "bar", "dependence"] = "summary",
    feature: str | None = None,
) -> None:
    """
    Save SHAP plots with consistent layout.

    Parameters
    ----------
    shap_vals
        SHAP values (n_samples, n_features)
    X
        Feature dataframe
    path
        Output file path
    plot_kind
        One of: 'summary', 'bar', 'dependence'
    feature
        Required if plot_kind == 'dependence'
    """
    plt.figure(figsize=(14, 0.35 * self.max_display))

    if plot_kind == "summary":
        shap.summary_plot(
            shap_vals,
            X,
            max_display=self.max_display,
            show=False,
        )

    elif plot_kind == "bar":
        shap.summary_plot(
            shap_vals,
            X,
            plot_type="bar",
            max_display=self.max_display,
            show=False,
        )

    elif plot_kind == "dependence":
        if feature is None:
            raise ValueError("feature must be provided for dependence plot")

        shap.dependence_plot(
            feature,
            shap_vals,
            X,
            show=False,
        )

    else:
        raise ValueError(f"Unsupported plot_kind: {plot_kind}")

    ax = plt.gca()

    # Reduce y-axis (feature name) font size
    for label in ax.get_yticklabels():
        label.set_fontsize(8)

    # Reduce x-axis tick font size
    for label in ax.get_xticklabels():
        label.set_fontsize(8)

    # Extra space for long feature names
    plt.gcf().subplots_adjust(left=0.35)

    plt.savefig(path, bbox_inches="tight")
    plt.close()

self._save_shap_plot(
    shap_vals=self.shap_oos,
    X=self.X_oos,
    path=output_dir / "dependence_feature_x.png",
    plot_kind="dependence",
    feature="feature_x",
)


