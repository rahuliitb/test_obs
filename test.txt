def challenger_model_randomsearch_or_cv(
    df: pd.DataFrame,
    numeric_cols: List[str],
    target_col: str,
    cv,
    groups: Optional[np.ndarray] = None,
    binning_fit_params: Optional[Dict[str, Any]] = None,
    iv_threshold: float = 0.02,
    min_features: int = 1,
    regularization: str = "l2",
    scoring: str = "roc_auc",
    tune_hyperparameters: bool = True,
    param_distributions: Optional[Dict[str, Any]] = None,
    n_iter: int = 20,
    n_jobs: int = -1,
    verbose: int = 0,
):
    """
    Returns:
        - iv_report
        - selected_features
        - final_model  (ALWAYS fitted)
        - If tuning:
            best_params, best_cv_score
        - If no tuning:
            cv_scores, mean_cv_score
    """

    # ----------------------------
    # 1) Expand binning params
    # ----------------------------
    bfp_raw = binning_fit_params or {}
    if isinstance(bfp_raw, dict) and "global" in bfp_raw:
        g = bfp_raw["global"] or {}
        per_var_map = {c: {**g, **(bfp_raw.get(c, {}) or {})} for c in numeric_cols}
    else:
        per_var_map = {c: (bfp_raw.get(c, {}) if isinstance(bfp_raw, dict) else {})
                       for c in numeric_cols}

    # ----------------------------
    # 2) IV computation
    # ----------------------------
    X_all = df[numeric_cols]
    y_all = df[target_col].values

    bp_iv = BinningProcess(variable_names=numeric_cols, binning_fit_params=per_var_map)
    bp_iv.fit(X_all, y_all)

    iv_df = (
        bp_iv.summary()[["variable", "iv"]]
        .sort_values("iv", ascending=False)
        .reset_index(drop=True)
    )

    # ----------------------------
    # 3) Strict IV selection
    # ----------------------------
    selected = iv_df[iv_df["iv"] >= iv_threshold]["variable"].tolist()
    if len(selected) < min_features:
        raise ValueError(
            f"Only {len(selected)} features >= IV {iv_threshold}, need >= {min_features}."
        )

    selected = [v for v in iv_df["variable"].tolist() if v in selected]
    X_sel = df[selected]

    # ----------------------------
    # 4) Build pipeline
    # ----------------------------
    solver = "lbfgs" if regularization == "l2" else "saga"

    selected_bfp = {v: per_var_map.get(v, {}) for v in selected}

    pipe = Pipeline([
        ("binning", BinningProcess(variable_names=selected, binning_fit_params=selected_bfp)),
        ("scaler", StandardScaler()),
        ("clf", LogisticRegression(max_iter=2000, solver=solver)),
    ])

    # ================================================================
    # MODE A — Hyperparameter tuning WITH refit=True
    # ================================================================
    if tune_hyperparameters:

        if param_distributions is None:
            param_distributions = {
                "clf__C": loguniform(1e-4, 1e1),
                "clf__class_weight": [None, "balanced"],
            }
            if regularization == "both":
                param_distributions["clf__penalty"] = ["l1", "l2"]

        rs = RandomizedSearchCV(
            estimator=pipe,
            param_distributions=param_distributions,
            n_iter=n_iter,
            scoring=scoring,
            cv=cv,
            refit=True,             # <<< IMPORTANT: refit ON full data
            verbose=verbose,
            n_jobs=n_jobs,
            random_state=42
        )

        rs.fit(X_sel, y_all, groups=groups)

        final_model = rs.best_estimator_     # fully fitted model

        return {
            "mode": "random_search",
            "iv_report": iv_df,
            "selected_features": selected,
            "best_params": rs.best_params_,
            "best_cv_score": rs.best_score_,
            "cv_results": rs.cv_results_,
            "final_model": final_model       # <<< fully fitted pipeline
        }

    # ================================================================
    # MODE B — No hyperparameter tuning
    # ================================================================
    else:
        cv_scores = cross_val_score(
            pipe, X_sel, y_all,
            cv=cv,
            groups=groups,
            scoring=scoring,
            n_jobs=n_jobs
        )

        # Fit once on full data
        final_model = pipe.fit(X_sel, y_all)

        return {
            "mode": "cv_only",
            "iv_report": iv_df,
            "selected_features": selected,
            "cv_scores": cv_scores.tolist(),
            "mean_cv_score": float(np.mean(cv_scores)),
            "final_model": final_model     # <<< fully fitted model
        }
